{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16a4419-6e7d-4d29-9083-da625331f5c8",
   "metadata": {},
   "source": [
    "# Summary Steps\n",
    "0. Load the env file\n",
    "1. Load the tweetQA dataset from HuggingFace.\n",
    "2. Create a model to communicate with ChatGPT.\n",
    "3. Set up ChatPromptTemplate for Q & A using the tweet\n",
    "4. Test the response\n",
    "5. Try running in batches \n",
    "6. Evaluate the results using Bleu, Meteor and Rogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74f828-8374-45e2-88e7-95a03dbb25e3",
   "metadata": {},
   "source": [
    "## Step 0 - Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63de906-116b-43d1-93e8-3a916dd84e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "hf_token = os.environ[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef242de4-f775-4b9f-8acb-e720d2944d06",
   "metadata": {},
   "source": [
    "## Step 1: Load the tweetQA dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e92991-c8f5-4d76-b39b-a82050caa474",
   "metadata": {},
   "source": [
    "from huggingface_hub import login\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac140c7-0e35-499f-813e-0515f31c5488",
   "metadata": {},
   "source": [
    "Load the dataset, save it to validate.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405ef27d-f1d9-492a-b0e1-c34fecb7b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
      "        num_rows: 10692\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
      "        num_rows: 1086\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
      "        num_rows: 1979\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98479cf7e3114f14b142960b9dc3204b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "332180"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, config\n",
    "import copy\n",
    "ds = load_dataset(\"ucsbnlp/tweet_qa\")\n",
    "# Show overall dataset\n",
    "print(ds)\n",
    "\n",
    "# Show the validation set\n",
    "ds_validation = ds['validation']\n",
    "\n",
    "# Set batch_size > validation-size to avoid json error later\n",
    "ds_validation.to_json(\"validate.json\", lines=False, batch_size=2000)\n",
    "#ds_prediction = copy.deepcopy(ds_validation)\n",
    "\n",
    "# Test change\n",
    "#ds_validation[0]['Answer'] = 'Test Answer'\n",
    "#print(ds_validation[0])\n",
    "#print(ds_prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e674d9-8b4f-4bd7-b80e-b1a1f213cb38",
   "metadata": {},
   "source": [
    "## Step 2 - Create a model to communicate with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454ceadb-de6b-4be5-b3cf-3bad0dc40b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Use gpt-4o-mini as this is the cheapest\n",
    "# Set temperature to 0 as we want a precise answer for higher score\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ea05e-852c-4d34-8bb3-f8c1db98e35e",
   "metadata": {},
   "source": [
    "## Step 3 - Set up ChatPromptTemplate for Q & A using the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb615c8c-df8e-4435-b4f8-42b37579626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template worked for single tweet-question pair\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You will be answering questions based on a tweet. Give the answer related to the question and tweet only. \"\n",
    "            \"Give a precise answer, no need to answer in a sentence\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf33a68d-ceb0-465e-bf0f-5419df2d9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template worked for multiple tweet-question pair\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You will be answering questions based on tweets. The total count of tweet and question pairs will be indicate at the beginning.\" + \n",
    "            \"Example, count:10 indicate there are total 10 tweets and 10 questions. So I will expect 10 answers\" +\n",
    "            \"The tweet will start with Tweet: . The question will start with Question: \" + \n",
    "            \"Each tweet and question pair will be separated by the exact keyword --next-- \" + \n",
    "            \"Return the answer for each question sorted according to the order of questions, separated with symbol #. No need to number the answer\" +\n",
    "            \"Give a precise answer, no need to answer in a sentence\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6f353-c1d0-4dae-8472-f9369215a495",
   "metadata": {},
   "source": [
    "### Step 3 - 1 : Create helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924f595-ccbc-4064-b0d2-0326e8bb3500",
   "metadata": {},
   "source": [
    "Helper function does the following things:\n",
    "1. Create batch messages from the validation dataset\n",
    "2. Get the response from the ChatGPT model using batch api from LangChain\n",
    "3. Store the response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c29d3433-f975-4f13-951c-6619cc4b6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing datetime module\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Batch prediction function \n",
    "def batch_prediction(data, results, start_idx:int, batch_size:int):\n",
    "    # Perform batch prediction based on start_idx in the dataset and batch_size\n",
    "    # Stored it in results\n",
    "    batch_messages = []\n",
    "    temp_results = []\n",
    "    minute2tk_cnts = []\n",
    "    test_message = f\"count:{batch_size} \"\n",
    "    for i in range(start_idx, start_idx + batch_size):\n",
    "        test_message += \"[\"\n",
    "        test_message += f\"Tweet:{ds_validation[i]['Tweet']}\"\n",
    "        test_message += ','\n",
    "        test_message += f\"Question:{ds_validation[i]['Question']}?\"\n",
    "        test_message += ']'\n",
    "        if i+1 != start_idx + batch_size:\n",
    "            test_message += '-next-'\n",
    "        temp_results.append(ds_validation[i])\n",
    "        \n",
    "        #batch_messages.append({\"messages\": [HumanMessage(content=test_message)]})\n",
    "    # print(test_message) \n",
    "    #responses = chain.batch(batch_messages)\n",
    "    start = timer()\n",
    "    response = chain.invoke({\"messages\": [HumanMessage(content=test_message)]})\n",
    "    end = timer()\n",
    "    print(f\"Query took {end - start} seconds\")\n",
    "    print(response.content)\n",
    "    print(response.usage_metadata[\"total_tokens\"])\n",
    "    time_obj = datetime.now()\n",
    "    answers_txt = response.content.strip()\n",
    "    answers = answers_txt.split(\"#\")\n",
    "    print(len(answers), len(temp_results))\n",
    "\n",
    "    for i,response in enumerate(answers):\n",
    "        if i < len(temp_results):\n",
    "            temp_results[i]['Answer'] = response\n",
    "    #print(temp_results)\n",
    "    \n",
    "    results.extend(temp_results)\n",
    "    # End \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1ea18-f88f-4ccc-b792-80f5525a0577",
   "metadata": {},
   "source": [
    "Set the list to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3334f58e-8554-4288-9199-ce6eb80d613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "pred_results = []\n",
    "\n",
    "# Reload previous result\n",
    "import json\n",
    "prev_results = json.load(open('prediction.json'))\n",
    "print(len(prev_results))\n",
    "pred_results.extend(prev_results)\n",
    "pred_results = pred_results[:120]\n",
    "print(len(pred_results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6d10f-3afc-4be1-9fe1-8dcbe89701a0",
   "metadata": {},
   "source": [
    "Call the function to obtain list of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0b7155ce-7396-42de-87c4-8236f98968e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 2.858128200052306 seconds\n",
      "Olympics#USA#Do Ya Think I'm Sexy#republicrecords#the Internet#Net Neutrality#Usher, Jimmy Fallon, Hamilton Musical cast#office workers#San Bernardino#Nate#14th#Golden Globes#black#unknown#sadness#1 dollar#@smosh#Erdogan#abuse#two scarves and a jacket#June#Patricia Arquette#half her life#Ellen DeGeneres and Portia#ellentube#David Levitz#stick together#protect DREAMERS#Sundance#unknown#Dunkirk#unknown#Sanders#94 crime bill#Grace VanderWaal#made her famous#Ryan#jazz#airwaves#write a book or start a podcast\n",
      "2813\n",
      "40 40\n"
     ]
    }
   ],
   "source": [
    "batch_prediction(ds_validation, pred_results, start_idx=80, batch_size=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a718634a-8169-45eb-b60c-b2cc0f8182b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 7.158819200005382 seconds\n",
      "Zac Efron#cheek#Dave Majewski#not surprised#thinkpieces#FyreFestival#not equal#year and a half#record#Sweden#FoxNews#four-shot lead#No. 17#emotions#multiple offers#Iowa flag#midfield#Ask Sheev#protect the American people#helping economy#Paul, Noma and Cherrelle#Harry Potter Play#official statement#heartbroken#Joss Whedon#BATGIRL#Nashville#Taylor#section 104#Mike Green#three-year deal#long-term deal#PR team#Zigi#crowd's mouths#prayers & hymns#boogieman#Alexander Pettyton#favorite part#PCL#hating on nomaj#the elephant#nervous#Boston#city#Team USA#lockerroom#Sterling K. Brown#proud#The Tig#sad#restroom#2014#LA#reaction#This Is What The Truth Feels Like TOUR#link#upper hand#Beyhive#tattoo#LeBron James#America#amber waves of grain#Ann Coulter#Delta#Fred Armisen#Difficult People#Governor Jay Nixon#fair#Carlton#Hotline Bling#Shia LaBeouf#surveillance images#December 29, 2017#shower#Saturday Night Live#flats#Gal Gadot#Bryzgalov#NHLAllStar#Selena & Abel#music#Trevor Story#thumb surgery#Rockies#purple#Kate Gosselin#travel headaches#central & eastern U.S.#photos#Kim Kardashian\n",
      "6243\n",
      "91 100\n"
     ]
    }
   ],
   "source": [
    "# Showing failed response\n",
    "batch_prediction(ds_validation, pred_results, start_idx=170, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a25b44-4f59-4983-a023-3a0f3546976f",
   "metadata": {},
   "source": [
    "Dumping result to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5b33c9-6906-4421-a10f-bf8bce9a7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"prediction_120.json\", \"w\") as final:\n",
    "    json.dump(pred_results, final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c5205-3c30-44e5-a4e7-083127266782",
   "metadata": {},
   "source": [
    "## Step 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ad0adf-d541-4534-bfca-a828edc4cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import json\n",
    "\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "\n",
    "# Importing the statistics module\n",
    "from statistics import mean\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "meteor_scorer = Meteor()\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "def ans_score(ans, gold_list):\n",
    "    ans = normalize_answer(ans)\n",
    "    gold_list = [normalize_answer(ref) for ref in gold_list]\n",
    "    bleu = sentence_bleu([_.split() for _ in gold_list], ans.split(), weights=(1,0,0,0))\n",
    "    meteor, _ = meteor_scorer.compute_score({0:gold_list}, {0:[ans]})\n",
    "    rouge, _ = rouge_scorer.compute_score({0:gold_list}, {0:[ans]})\n",
    "    return [bleu, meteor, rouge]\n",
    "\n",
    "def evaluate(test_annotation_file, user_annotation_file, phase_codename, **kwargs):\n",
    "    gold_file = test_annotation_file\n",
    "    pred_file = user_annotation_file\n",
    "    gold = json.load(open(gold_file))\n",
    "    pred = json.load(open(pred_file))\n",
    "    idx2gold = {item['qid']:item['Answer'] for item in gold}\n",
    "    idx2pred = {item['qid']:item['Answer'] for item in pred}\n",
    "    idx2scores = {}\n",
    "    for id_ in idx2gold.keys():\n",
    "        # Skip when prediction results not available\n",
    "        if id_ not in idx2pred:\n",
    "            continue\n",
    "        if isinstance(idx2pred[id_], list):\n",
    "            pred_ans = idx2pred[id_][0]\n",
    "        else:\n",
    "            pred_ans = idx2pred[id_]\n",
    "        idx2scores[id_] = ans_score(pred_ans, idx2gold[id_])\n",
    "\n",
    "    # Test print\n",
    "    # print(idx2scores)\n",
    "    bleus = [item[0] for item in idx2scores.values()]\n",
    "    meteors = [item[1] for item in idx2scores.values()]\n",
    "    rouges = [item[2] for item in idx2scores.values()]\n",
    "    print({'BLEU': np.mean(bleus), 'METEOR': np.mean(meteors), 'ROUGE': np.mean(rouges)})\n",
    "\n",
    "    output = {}\n",
    "    output['result'] = [\n",
    "    {'test_split': \n",
    "        {\n",
    "        'BLEU-1': np.mean(bleus),\n",
    "        'METEOR': np.mean(meteors),\n",
    "        'ROUGE': np.mean(rouges)\n",
    "        }\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0aa4318-c3cc-4e51-8869-d4ccd7d1273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLEU': 0.7354816502173205, 'METEOR': 0.6962335040048635, 'ROUGE': 0.7723241380264703}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': [{'test_split': {'BLEU-1': 0.7354816502173205,\n",
       "    'METEOR': 0.6962335040048635,\n",
       "    'ROUGE': 0.7723241380264703}}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test evaluate function\n",
    "evaluate(\"validate.json\",\"prediction_120.json\", \"ChatGPT4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83101c-3464-4ed1-bc44-0b4beed85dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
