{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16a4419-6e7d-4d29-9083-da625331f5c8",
   "metadata": {},
   "source": [
    "# Summary Steps\n",
    "0. Load the env file\n",
    "1. Load the tweetQA dataset from HuggingFace.\n",
    "2. Create a model to communicate with ChatGPT.\n",
    "3. Set up ChatPromptTemplate for Q & A using the tweet\n",
    "4. Test the response\n",
    "5. Try running in batches \n",
    "6. Evaluate the results using Bleu, Meteor and Rogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74f828-8374-45e2-88e7-95a03dbb25e3",
   "metadata": {},
   "source": [
    "## Step 0 - Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b63de906-116b-43d1-93e8-3a916dd84e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "hf_token = os.environ[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef242de4-f775-4b9f-8acb-e720d2944d06",
   "metadata": {},
   "source": [
    "## Step 1: Load the tweetQA dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e92991-c8f5-4d76-b39b-a82050caa474",
   "metadata": {},
   "source": [
    "from huggingface_hub import login\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac140c7-0e35-499f-813e-0515f31c5488",
   "metadata": {},
   "source": [
    "Load the dataset, save it to validate.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "405ef27d-f1d9-492a-b0e1-c34fecb7b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
      "        num_rows: 10692\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
      "        num_rows: 1086\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
      "        num_rows: 1979\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
      "    num_rows: 1086\n",
      "})\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934f01f69be94836a4fad904b4ec52a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "332180"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, config\n",
    "\n",
    "ds = load_dataset(\"ucsbnlp/tweet_qa\")\n",
    "# Show overall dataset\n",
    "print(ds)\n",
    "\n",
    "# Show the validation set\n",
    "ds_validation = ds['validation']\n",
    "print(ds_validation)\n",
    "print(config.DEFAULT_MAX_BATCH_SIZE)\n",
    "ds_validation.to_json(\"validate.json\", lines=False, batch_size=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e674d9-8b4f-4bd7-b80e-b1a1f213cb38",
   "metadata": {},
   "source": [
    "## Step 2 - Create a model to communicate with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "454ceadb-de6b-4be5-b3cf-3bad0dc40b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Use gpt-4o-mini as this is the cheapest\n",
    "# Set temperature to 0 as we want a precise answer for higher score\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ea05e-852c-4d34-8bb3-f8c1db98e35e",
   "metadata": {},
   "source": [
    "## Step 2 - Set up ChatPromptTemplate for Q & A using the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb615c8c-df8e-4435-b4f8-42b37579626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You will be answering questions based on a tweet. Give the answer related to the question and tweet only. \"\n",
    "            \"Give a precise answer, no need to answer in a sentence\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6f353-c1d0-4dae-8472-f9369215a495",
   "metadata": {},
   "source": [
    "### Step 2 - 1 : Check first response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec811dd-1f22-4db6-92b1-0ff3d97b5176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The police dogs who patrol the area.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_message = \"Tweet:The police dogs who patrol the area are some of my favorite faces to see around the Capitol. # Sen. Al Franken (@SenFranken) August 26, 2017\"\n",
    "test_message += ','\n",
    "test_message += \"Question:who are some of Franken's favorite faces to see?\"\n",
    "response = chain.invoke({\"messages\": [HumanMessage(content=test_message)]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05bbf159-728a-4307-9bfd-e8e6543ca4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Independence High School'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_message = \"Tweet:Our prayers are with the students, educators & families at Independence High School & all the first responders on the scene. #PatriotPride\\u2014 Doug Ducey (@dougducey) February 12, 2016\"\n",
    "test_message += ','\n",
    "test_message += \"Question:at which school were first responders on the scene for?\"\n",
    "response = chain.invoke({\"messages\": [HumanMessage(content=test_message)]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924f595-ccbc-4064-b0d2-0326e8bb3500",
   "metadata": {},
   "source": [
    "Prepare the prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25bf96a1-a239-41f1-987f-3ea6a0e09d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfeab733fe5422cbd74a2ef30daf656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "332180"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_validation.to_json(\"prediction.json\", lines=False, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beda5249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb950b8060f4c10a0718c5a28d45ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "332178"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_validation.to_json(\"validate2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29d3433-f975-4f13-951c-6619cc4b6c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:This forecast is deflated as much as New England Patriots footballs! I apologize. W NJ has the most to lose. Dave Curren (@DaveCurren) January 27, 2015,Question:who has the most to lose?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'W NJ'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_message = f\"Tweet:{ds_validation[0]['Tweet']}\"\n",
    "test_message += ','\n",
    "test_message += f\"Question:{ds_validation[0]['Question']}?\"\n",
    "print(test_message)\n",
    "response = chain.invoke({\"messages\": [HumanMessage(content=test_message)]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3334f58e-8554-4288-9199-ce6eb80d613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:This forecast is deflated as much as New England Patriots footballs! I apologize. W NJ has the most to lose. Dave Curren (@DaveCurren) January 27, 2015,Question:who has the most to lose?\n",
      "Tweet:This forecast is deflated as much as New England Patriots footballs! I apologize. W NJ has the most to lose. Dave Curren (@DaveCurren) January 27, 2015,Question:what is deflated as much as the new england patriot footballs?\n",
      "W NJ\n",
      "The forecast.\n"
     ]
    }
   ],
   "source": [
    "test_message1 = f\"Tweet:{ds_validation[0]['Tweet']}\"\n",
    "test_message1 += ','\n",
    "test_message1 += f\"Question:{ds_validation[0]['Question']}?\"\n",
    "print(test_message1)\n",
    "\n",
    "test_message2 = f\"Tweet:{ds_validation[1]['Tweet']}\"\n",
    "test_message2 += ','\n",
    "test_message2 += f\"Question:{ds_validation[1]['Question']}?\"\n",
    "print(test_message2)\n",
    "responses = chain.batch([{\"messages\": [HumanMessage(content=test_message1)]}, {\"messages\": [HumanMessage(content=test_message2)]}])\n",
    "\n",
    "for response in responses:\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2bf4817-97f4-434f-a970-a61a56fb57a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W NJ\n",
      "<class 'str'>\n",
      "The forecast.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "    print(response.content)\n",
    "    print(type(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c5205-3c30-44e5-a4e7-083127266782",
   "metadata": {},
   "source": [
    "## Now import the evaluation formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05ad0adf-d541-4534-bfca-a828edc4cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import json\n",
    "\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "\n",
    "# Importing the statistics module\n",
    "from statistics import mean\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "meteor_scorer = Meteor()\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "def ans_score(ans, gold_list):\n",
    "    ans = normalize_answer(ans)\n",
    "    gold_list = [normalize_answer(ref) for ref in gold_list]\n",
    "    bleu = sentence_bleu([_.split() for _ in gold_list], ans.split(), weights=(1,0,0,0))\n",
    "    meteor, _ = meteor_scorer.compute_score({0:gold_list}, {0:[ans]})\n",
    "    rouge, _ = rouge_scorer.compute_score({0:gold_list}, {0:[ans]})\n",
    "    return [bleu, meteor, rouge]\n",
    "\n",
    "def evaluate(test_annotation_file, user_annotation_file, phase_codename, **kwargs):\n",
    "    gold_file = test_annotation_file\n",
    "    pred_file = user_annotation_file\n",
    "    gold = json.load(open(gold_file))\n",
    "    pred = json.load(open(pred_file))\n",
    "    idx2gold = {item['qid']:item['Answer'] for item in gold}\n",
    "    idx2pred = {item['qid']:item['Answer'] for item in pred}\n",
    "    idx2scores = {}\n",
    "    for id_ in idx2gold.keys():\n",
    "        if isinstance(idx2pred[id_], list):\n",
    "            pred_ans = idx2pred[id_][0]\n",
    "        else:\n",
    "            pred_ans = idx2pred[id_]\n",
    "        idx2scores[id_] = ans_score(pred_ans, idx2gold[id_])\n",
    "    bleus = [item[0] for item in idx2scores.values()]\n",
    "    meteors = [item[1] for item in idx2scores.values()]\n",
    "    rouges = [item[2] for item in idx2scores.values()]\n",
    "    print({'BLEU': np.mean(bleus), 'METEOR': np.mean(meteors), 'ROUGE': np.mean(rouges)})\n",
    "\n",
    "    output = {}\n",
    "    output['result'] = [\n",
    "    {'test_split': \n",
    "        {\n",
    "        'BLEU-1': np.mean(bleus),\n",
    "        'METEOR': np.mean(meteors),\n",
    "        'ROUGE': np.mean(rouges)\n",
    "        }\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0aa4318-c3cc-4e51-8869-d4ccd7d1273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLEU': 1.0, 'METEOR': 1.0, 'ROUGE': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': [{'test_split': {'BLEU-1': 1.0, 'METEOR': 1.0, 'ROUGE': 1.0}}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test evaluate function\n",
    "evaluate(\"validate.json\",\"prediction.json\", \"ChatGPT3.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83101c-3464-4ed1-bc44-0b4beed85dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
